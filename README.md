# stock-pattern-recorginition

# TensorFlow Object Detection Model Training

This is a summary of [this nice tutorial]( https://medium.com/towards-data-science/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9).

1. [Install TensorFlow](https://www.tensorflow.org/install/).

2. Download the TensorFlow [models repository](https://github.com/tensorflow/models).

## Annotating the dataset

1. Install [labelImg](https://github.com/tzutalin/labelImg). This is a Python package, you can install via pip, but the one from GitHub is better. It saves annotations in the PASCAL VOC format.

2. Annotate your dataset using labelImg.

3. Use [this script](https://github.com/datitran/raccoon_dataset/blob/master/xml_to_csv.py) to convert the XML files generated by labelImg into a single CSV file.

    cd get_data/
    
      python xml2csv.py 

4. Separate the CSV file into two, one with training examples and one with evaluation examples. Images should be selected randomly, making sure that objects from all classes are present in both of them. The usual proportions are 75 to 80% training and the rest to the evaluation dataset.

5. Use [this script](https://github.com/datitran/raccoon_dataset/blob/master/generate_tfrecord.py) to convert the two CSV files (eg. train.csv and eval.csv) into TFRecord files (eg. train.record and eval.record), the data format TensorFlow is most familiar with.

    get_data/
    
    $ python general_tf_record.py --csv_input=label_training/raccoon_labels.csv --output_path=label_training/train.record

## Traversing the text file hell...

6. Create a label map, like [one of these](https://github.com/tensorflow/models/tree/master/research/object_detection/data). Make sure class numbers are exactly the ones that were used when creating the TFRecords.

7. Download one of the neural network models provided in [this page](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md). The ones trained in the MSCoco dataset are the best ones, since they were also trained on objects.

8. Provide a training pipeline, which is a `config` that usually comes in the tar.gz file downloaded in the last step. If they don't, they can be found [here]( https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs) (they need some tweaking before using, for example, changing number of classes). A tutorial on how to create your own [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md).

 * The pipeline config file has some fields that must be adjusted before training is started. Its header describes which ones. Usually, they are the fields that point to the label map, the training and evaluation directories and the neural network checkpoint. In case you downloaded one of the models provided in [this page](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md), you should untar the `tar.gz` file and point the checkpoint path inside the pipeline config file to the "untarred" directory of the model (see [this answer](https://stackoverflow.com/a/45363576/1245214) for help).

 * You should also check the number of classes. MSCoco has 90 classes, but your problem may have more or less.

## Training the network

1. Train the model. [This is how you do it locally](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_locally.md). **Optional:** in order to check training progress, TensorBoard can be started pointing its `--logdir`  to the `--train_dir` of object_detection/train.py.

2. Export the network, like [this](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/exporting_models.md).

3. Use the exported `.pb` in your object detector.

## Tips

In the _data augmentation_ section of the training pipeline, some options can be added or removed to try and make the training better. Some of the options are listed [here](https://stackoverflow.com/a/46901051)

1. If you are running out of memory and this is causing training to fail, there are a number of solutions you can try. First try adding  the arguments

      batch_queue_capacity: 2
      
      prefetch_queue_capacity: 2
  
  to your config file in the train_config section. For example, placing the two lines between gradient_clipping_by_norm and fine_tune_checkpoint will work. The number 2 above should only be starting values to get training to begin. The default for those values are 8 and 10 respectively and increasing those values should help speed up training.
